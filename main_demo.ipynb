{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    .dothis{\n",
       "    font-weight: bold;\n",
       "    color: #ff7f0e;\n",
       "    font-size:large\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    .dothis{\n",
    "    font-weight: bold;\n",
    "    color: #ff7f0e;\n",
    "    font-size:large\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of the Swiss Data Cube <a name=\"top\"></a>\n",
    "\n",
    "This notebook introduces you to the Swis Data Cube. It has the following sections:\n",
    "\n",
    "- **[Standard script/notebook beginning](#standbeg)**: To run cells from other sections you first need to run all cells of this section.\n",
    "\n",
    "- **[Load a data cube](#loaddcoptb)**: loads a datacube (into an `xarray.Dataset`) for further analysis.\n",
    "    \n",
    "- **[Explore created data cube](#explorexr)**: explore the created `xarray.Dataset` variable (dataset_clean).\n",
    "\n",
    "- **[Create, plot and export mosaic figure using default data cube functions](#pngdef)**\n",
    "\n",
    "- **[Plot and export mosaic figure using Swiss Data Cube functions](#pngsdc)**\n",
    "\n",
    "- **[Export `xarray.Dataset`](#exportds)**\n",
    "\n",
    "- **[Create, plot and export `xarray.DataArray`](#dataarray)**\n",
    "\n",
    "- **[Water time series analysis](#waterts)**\n",
    "\n",
    "- **[Extracting time series at a point](#tsextract)**\n",
    "    \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard script beginning <a name=\"standbeg\"></a>\n",
    "\n",
    "The cells in this section are generally found at the beginning of a script (and it is advised to re-use this template in all new notebooks you make).\n",
    "\n",
    "To run cells from above sections you need to run all cells of this section.\n",
    "\n",
    "- **import dependencies**: import libraries, connect to datacube.\n",
    "- **Configuration**: all variables you might need to change. Keep in mind that the larger it will be (in terms of geograhical extent, time period and number of measurements (bands)), the slower the loading will go.\n",
    "- **Functions**: all functions written in-script\n",
    "[<div style=\"text-align: right; font-size: 24px\"> &#x1F51D; </div>](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the script is using the correct kernel (see also the README)\n",
    "try:\n",
    "    %run ../swiss_utils/assert_env.py\n",
    "except:\n",
    "    %run ./swiss_utils/assert_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "# reload module before executing code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# define modules locations (you might have to adapt define_mod_locs.py)\n",
    "%run ./swiss_utils/define_mod_locs.py\n",
    "\n",
    "# to plot figures\n",
    "%matplotlib inline\n",
    "\n",
    "# import full general libraries\n",
    "\n",
    "# import general libraries and allocate them a specific name\n",
    "import numpy as np # np.average\n",
    "import pandas as pd # DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import specific functions from general libraries\n",
    "from datetime import datetime\n",
    "from IPython.display import Image, display, HTML\n",
    "from matplotlib import colors\n",
    "\n",
    "# import dedicated function of general libraries\n",
    "\n",
    "# import ODC (default) functions\n",
    "from utils.data_cube_utilities.dc_mosaic import create_hdmedians_multiple_band_mosaic\n",
    "from utils.data_cube_utilities.dc_utilities import write_png_from_xr\n",
    "from utils.data_cube_utilities.dc_water_classifier import wofs_classify\n",
    "\n",
    "# import SDC functions\n",
    "from swiss_utils.data_cube_utilities.sdc_utilities import ls_qa_clean, load_multi_clean, \\\n",
    "                                                          write_geotiff_from_xr, time_list\n",
    "from swiss_utils.data_cube_utilities.sdc_advutils import oneband_fig, composite_fig\n",
    "\n",
    "# connect to DC\n",
    "import datacube\n",
    "dc = datacube.Datacube()\n",
    "\n",
    "# silence warning (not recommended during development)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the data cube\n",
    "The next cell contains the data cube configuration information:\n",
    "\n",
    "- product\n",
    "- geographical extent\n",
    "- time period\n",
    "- bands\n",
    "\n",
    "You can create it in three ways:\n",
    "1. by loading the final cell content of the [config_tool](config_tool.ipynb) notebook using the magic `%load config_cell.txt`.\n",
    "2. by manually copy/pasting the final cell content of the [config_tool](config_tool.ipynb) notebook,\n",
    "3. manually by typing it out.\n",
    "\n",
    "Apply the following rules when generating the configuration cell:\n",
    "- select a **small dataset** (geograhical extent, time period and number of measurements (bands)) for faster processing,\n",
    "- select an **area covering only a small parts of mountains** (as snow is generally confused with clouds and then considered as nodata),\n",
    "- If selecting winter, **be careful** as the chances of confusing clouds and snow are higher.\n",
    "\n",
    "Specifically for this demo:\n",
    "- Use **landsat - but not any Landsat 7 product** (as it contains large part of nodata since 2003),\n",
    "- **The following measurements are required**: `red, green, blue, nir, swir1, swir2` and `pixel_qa`\n",
    "- the geographical extent should **contain some water/a lake** as water detection tools will be used.\n",
    "\n",
    "\n",
    "Now:\n",
    "<ul class=\"dothis\">\n",
    "    <li>Use the config_tool to create <tt>config_cell.txt</tt>.</li>\n",
    "    <li>Execute the cell below to load the contents of <tt>config_cell.txt</tt>.</li>\n",
    "    <li>Execute the cell below again so that Python reads/executes the variables.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load config_cell.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data cube<a name=\"loaddcoptb\"></a>\n",
    "\n",
    "Load requested data cube (meaning an [xarray.Dataset](http://xarray.pydata.org/en/stable/index.html) variable will be created) based on configuration parameters, using [load_multi_clean](demo_FUN_load_multi_clean.ipynb).\n",
    "\n",
    "This function loads several products (in the same xarray.Dataset), cleans it and generates a mask.\n",
    "\n",
    "Various masking functions are available from the Open Data Cube libraries and the SDC, each one giving slightly different results. The function `load_multi_clean`:\n",
    "\n",
    "- can process Landsat as well as **Sentinel 2** data cubes\n",
    "- with Landsat, gives **priority to snow** when there is a low probability of cloud cover\n",
    "- can load **several products** at once.\n",
    "\n",
    "**load_multi_clean** generates two outputs:\n",
    "\n",
    "- a clean `xarray.Dataset`\n",
    "- a boolean mask `numpy.ndarray`\n",
    "\n",
    "Documentation for a given function can be accessed simply by adding ? at the end of the function in a cell. e.g. `load_multi_clean?` or by selecting the function and pressing `Shift-Tab`.\n",
    "[<div style=\"text-align: right; font-size: 24px\"> &#x1F51D; </div>](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a cube using SDC load_multi_clean function which will generate a clean dataset\n",
    "# Sometimes this doesn't work the first time - if not, re-execute the %load config_cell.txt cell then try again!\n",
    "\n",
    "dataset_clean, clean_mask = load_multi_clean(dc = dc,\n",
    "                                             products = product ,\n",
    "                                             time = [start_date, end_date],\n",
    "                                             lon = (min_lon, max_lon),\n",
    "                                             lat = (min_lat, max_lat),\n",
    "                                             measurements = measurements \n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the contents of the datacube we've loaded\n",
    "dataset_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot an histogram of green band\n",
    "dataset_clean.green.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the created xarray.Dataset variable (dataset_clean) <a name=\"explorexr\"></a>\n",
    "[<div style=\"text-align: right; font-size: 24px\"> &#x1F51D; </div>](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at dimensions\n",
    "dataset_clean.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of time points in the cube\n",
    "print('time count: %s\\n' % (len(dataset_clean.time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at time dimension\n",
    "dataset_clean.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nicely display time values using pandas library\n",
    "pd.DataFrame(dataset_clean.time, columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize specific red band\n",
    "# an xarray.Dataset variable consists in an xarray.DataArray\n",
    "dataset_clean.red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize specific red band for a given time index\n",
    "# remember in Python indexing starts at 0\n",
    "dataset_clean.red.isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot green band for all time\n",
    "\n",
    "dataset_clean.green.plot(x='longitude', y='latitude', col='time', col_wrap=5, cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot composites in True color (red, green, blue)\n",
    "# robust=True guesses the minimum and maximum values for each image.\n",
    "dataset_clean[['red','green','blue']].to_array().plot.imshow(col='time',col_wrap=5, robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create, plot and export mosaic figure<a name=\"pngdef\"></a>[<div style=\"text-align: right; font-size: 24px\"> &#x1F51D; </div>](#top)\n",
    "Across the whole geographical area, we can combine all our different satellite images into one composite/mosaic that represents the time period of interest. Here we export to the `png` format, which is very suitable for your project reports. Note that pngs do not have georeferencing information, so they cannot be read by GIS software such as QGIS. See later in this demo for how to create GeoTIFFs (`tif`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mosaic\n",
    "# several mosaic function (and options) are available:\n",
    "# - create_mosaic(dataset_in, clean_mask)\n",
    "# - create_mosaic(dataset_in.sortby('time', ascending = False)\n",
    "# - create_mean_mosaic(dataset_in)\n",
    "# - create_median_mosaic(dataset_in)\n",
    "# - create_min_ndvi_mosaic(dataset_in, clean_mask)\n",
    "# - create_max_ndvi_mosaic(dataset_in, clean_mask)\n",
    "# - create_hdmedians_multiple_band_mosaic(dataset_in, clean_mask, operation='median')\n",
    "# - create_hdmedians_multiple_band_mosaic(dataset_in, clean_mask, operation='medoid')\n",
    "\n",
    "# we will apply the last one at it seems to be the best balance betwee visual result an processing time\n",
    "mosaic = create_hdmedians_multiple_band_mosaic(dataset_clean, clean_mask, operation='medoid')\n",
    "mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot mosaic the default way\n",
    "mosaic[['red','green','blue']].to_array().plot.imshow(x='longitude', y='latitude', robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export mosaic as composite png the default way\n",
    "write_png_from_xr('demo_mosaic.png', mosaic ,['red', 'green', 'blue'])\n",
    "\n",
    "# png can be downloaded and visualized through the Home page of the Jupyter interface\n",
    "# but it can also be visualized in the notebook\n",
    "Image('demo_mosaic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might find the image a bit lighter (or darker), then let's find dataset values distribution\n",
    "kwargs = dict(bins = 50, alpha = 0.3)\n",
    "\n",
    "mosaic.red.plot.hist(color='red', **kwargs)\n",
    "mosaic.green.plot.hist(color='green', **kwargs, stacked = True)\n",
    "mosaic.blue.plot.hist(color='blue', **kwargs, stacked = True)\n",
    "plt.xlabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improve rendering using scale option\n",
    "# and display the png\n",
    "\n",
    "write_png_from_xr('demo_mosaic_scaled.png', mosaic ,['red', 'green', 'blue'], scale = [(0,2000),(0,2000),(0,2000)])\n",
    "\n",
    "Image('demo_mosaic_scaled.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and export mosaic figure the Swiss Data Cube way<a name=\"pngsdc\"></a>\n",
    "\n",
    "This adds bonus features such as a title, scale bar...\n",
    "\n",
    "For documentation run a cell containing:\n",
    "\n",
    "`composite_fig?`\n",
    "[<div style=\"text-align: right; font-size: 24px\"> &#x1F51D; </div>](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export previous mosaic as composite png the SDC way\n",
    "\n",
    "composite_fig(mosaic,\n",
    "              bands = ['red', 'green', 'blue'],\n",
    "              title = 'Demo composite',\n",
    "              scalebar_color = 'white',\n",
    "              max_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the demo let's reduce the figure size and stretch the image histogram\n",
    "\n",
    "composite_fig(mosaic,\n",
    "              bands = ['red', 'green', 'blue'],\n",
    "              title = 'Demo composite',\n",
    "              scalebar_color = 'white',\n",
    "              max_size = 10,\n",
    "              hist_str = 'contr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to export the composite as png, simply add the fig_name parameter\n",
    "\n",
    "composite_fig(mosaic,\n",
    "              bands = ['red', 'green', 'blue'],\n",
    "              title = 'Demo composite',\n",
    "              scalebar_color = 'white',\n",
    "              max_size = 10,\n",
    "              hist_str = 'contr',\n",
    "              fig_name = 'demo_composite.png')\n",
    "\n",
    "# when a png is created the composite is not displayed, but it can be downloaded and visualized\n",
    "# through the Home page of the Jupyter interface or added to the notebook with the command:\n",
    "Image('demo_composite.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Export xarray.Dataset <a name=\"exportds\"></a>[<div style=\"text-align: right; font-size: 24px\"> &#x1F51D; </div>](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export mosaic (xarray.Dataset) as a multi-band (containing all bands) NetCDF\n",
    "mosaic.to_netcdf('mosaic.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can re-load this later, which is very useful to avoid having to query the DataCube every time!\n",
    "import xarray as xr\n",
    "mosaic_from_disk = xr.open_dataset('mosaic.nc')\n",
    "mosaic_from_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export a GeoTIFF - can be added straight into software like QGIS/ArcGIS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For documentation run a cell containing: `write_geotiff_from_xr?`\n",
    "\n",
    "# As the CRS information was lots during mosaic creation it has to be precised in the next function\n",
    "\n",
    "write_geotiff_from_xr('mosaic.tif', mosaic, crs = dataset_clean.crs, compr = 'DEFLATE')\n",
    "\n",
    "# add a direct link (user might have to use Shift + Right click to save the link).\n",
    "display(HTML(\"\"\"<a href=\"mosaic.tif\" target=\"_blank\" >download geotiff</a>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Normalized Difference Indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start computing NDVI for each time\n",
    "\n",
    "ndvi = (dataset_clean.nir - dataset_clean.red) / (dataset_clean.nir + dataset_clean.red)\n",
    "ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then compute mean NDVI of the full time period\n",
    "ndvi_mean = ndvi.mean(dim=['time'])\n",
    "\n",
    "# replace +-Inf by nan\n",
    "ndvi_mean = ndvi_mean.where(np.isfinite(ndvi_mean))\n",
    "ndvi_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ndvi_mean the default way (as in previous sections, but by using custom NDVI colors\n",
    "# and fixed extreme colors/values)\n",
    "\n",
    "ndvi_mean.plot.imshow(x='longitude', y='latitude', vmin=-1, vmax=1,\n",
    "                      cmap = colors.LinearSegmentedColormap.from_list('ndvi', ['darkblue','blue','lightblue', \\\n",
    "                                                                               'lightgreen','darkgreen'], N=256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent plot the SDC way (oneband_fig function)\n",
    "\n",
    "oneband_fig(ndvi_mean,\n",
    "            leg = colors.LinearSegmentedColormap.from_list('ndvi', ['darkblue','blue','lightblue',\n",
    "                                                                    'lightgreen','darkgreen'], N=256),\n",
    "            title = 'NDVI mean with a gold scalebar',\n",
    "            scalebar_color = 'gold',\n",
    "            max_size = 16,\n",
    "            v_min = -1,\n",
    "            v_max = 1)\n",
    "\n",
    "# Compare the figure width/height ratio for default output and the Swiss Data Cube option.\n",
    "# Notice how the x and y resolution differ in the above figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export a DataArray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as NetCDF\n",
    "\n",
    "ndvi_mean.to_netcdf('ndvi_mean.nc')\n",
    "display(HTML(\"\"\"<a href=\"ndvi_mean.nc\" target=\"_blank\" >download NetCDF</a>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as geotiff\n",
    "# xarray.DataArray need to be converted to xarray.Dataset and the CRS to be defined\n",
    "\n",
    "write_geotiff_from_xr('ndvi_mean.tif', ndvi_mean.to_dataset(name = 'NDVI'), ['NDVI'],\n",
    "                      crs = dataset_clean.crs, compr = 'DEFLATE')\n",
    "display(HTML(\"\"\"<a href=\"ndvi_mean.tif\" target=\"_blank\" >download geotiff</a>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute NDWI and NDBI by combining the 2 commands (then we do not need to delete intermediate index)\n",
    "\n",
    "ndwi_mean = ((dataset_clean.green - dataset_clean.nir) / (dataset_clean.green + dataset_clean.nir)).mean(dim=['time'])\n",
    "ndwi_mean = ndwi_mean.where(np.isfinite(ndwi_mean)) # replace +-Inf by nan\n",
    "ndbi_mean = ((dataset_clean.swir2 - dataset_clean.nir) / (dataset_clean.swir2 + dataset_clean.nir)).mean(dim=['time'])\n",
    "ndbi_mean = ndbi_mean.where(np.isfinite(ndbi_mean)) # replace +-Inf by nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fun let's create a false color composite using Built, Vegetation and Water indexes\n",
    "\n",
    "# create a dataset with the 3 bands\n",
    "bvw_ds = ndbi_mean.to_dataset(name = 'ndbi').merge(ndvi_mean.to_dataset(name = 'ndvi')).merge(ndwi_mean.to_dataset(name = 'ndwi'))\n",
    "# delete the variable we do not need anymore\n",
    "del ndbi_mean\n",
    "del ndvi_mean\n",
    "del ndwi_mean\n",
    "# fix nan issues\n",
    "bvw_ds = bvw_ds.fillna(bvw_ds.min())\n",
    "bvw_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bvw_ds.ndbi.plot.hist(bins = 50, color='red', alpha = 0.3)\n",
    "bvw_ds.ndvi.plot.hist(bins = 50, color='green', alpha = 0.3, stacked = True)\n",
    "bvw_ds.ndwi.plot.hist(bins = 50, color='blue', alpha = 0.3, stacked = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally create a figure with fixed display range (-1 to +1 as we are dealing with normalized indexes)\n",
    "composite_fig(bvw_ds,\n",
    "              bands = ['ndbi', 'ndvi', 'ndwi'],\n",
    "              title = 'Demo BVW composite (with color range fixed to -1 to 1)',\n",
    "              scalebar_color = 'white',\n",
    "              max_size = 14,\n",
    "              v_min = -1,\n",
    "              v_max = 1,\n",
    "              fig_name = 'demo_BVW_composite.png')\n",
    "\n",
    "# and diplay it\n",
    "Image('demo_BVW_composite.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single time water time series analysis <a name=\"waterts\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run the \"Water Observation From Space\" algorithm\n",
    "# replace nodata values (-9999) by nan\n",
    "# compute percentage of time a pixel was detected as water\n",
    "\n",
    "# by default this function displays several warnings, we are turning them off...\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ts_water_classification = wofs_classify(dataset_clean, clean_mask = clean_mask)\n",
    "ts_water_classification = ts_water_classification.where(ts_water_classification != -9999)\n",
    "water_classification_percentages = (ts_water_classification.mean(dim = ['time']) * 100).wofs.rename('water_classification_percentages')\n",
    "\n",
    "# display water percentage\n",
    "water_classification_percentages.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display values distribution\n",
    "\n",
    "water_classification_percentages.plot.hist(bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: Extracting and plotting data through time <a name=\"tsextract\"></a>\n",
    "We will be covering time series analysis in much more detail on Friday morning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's show a map of the area where the current data cube covers.\n",
    "from shapely.geometry import Polygon\n",
    "from swiss_utils.data_cube_utilities.sdc_utilities import new_get_query_metadata\n",
    "from swiss_utils.data_cube_utilities.sdc_advutils import draw_map\n",
    "\n",
    "# We need the coordinate reference system of the product we are looking at.\n",
    "mtd = new_get_query_metadata(dc, product)\n",
    "crs = mtd['crs']\n",
    "\n",
    "# Add an empty map you can draw on it\n",
    "m, drawn_features = draw_map([min_lat, max_lat], [min_lon, max_lon], 'epsg:4326', draw=False)\n",
    "from ipyleaflet import DrawControl\n",
    "draw_c = DrawControl(marker={'shapeOptions': {'color': '#0000FF'}},\n",
    "                 polyline={},\n",
    "                 circle={},\n",
    "                 circlemarker={},\n",
    "                 polygon={}\n",
    "                )\n",
    "m.add_control(draw_c)\n",
    "print('Within the red rectangle, zoom, pan and then, using the Marker tool on the left, place a marker where you want to extract a time series:')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = draw_c.last_draw['geometry']['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi.sel(latitude=coords[0], longitude=coords[1], method='nearest').plot(marker='o', linestyle='none')\n",
    "plt.ylabel('NDWI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a certain time period in more detail\n",
    "ndvi.sel(latitude=coords[0], longitude=coords[1], method='nearest').sel(time=slice('2021-02-01', '2021-04-25')).plot(marker='o', linestyle='none')\n",
    "plt.ylabel('NDWI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can convert our time series to a Pandas series for more examination\n",
    "ndvi_at_point = ndvi.sel(latitude=coords[0], longitude=coords[1], method='nearest').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_at_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's resample to a monthly data series. Monthly values are calculated as the median of all values in the month.\n",
    "ndvi_pt_monthly = ndvi_at_point.resample('1M').median()\n",
    "ndvi_pt_monthly.plot(marker='x', linestyle='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now let's export to Comma Separated Format, CSV - this can be opened by other programs like Excel.\n",
    "ndvi_pt_monthly.to_csv('ndvi_at_pt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also generate a time series plot of the whole datacube area\n",
    "ndvi.median(dim=('longitude','latitude')).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "*****\n",
    "\n",
    "# Reprojection\n",
    "\n",
    "*****\n",
    "\n",
    "All the operations above we carried out using a CRS (coordinate reference system) of latitude and longitude called WGS84 (its code is *EPSG:4326*). You might have noticed that this CRS is displaying things with units of latitude and longitude. The images look compressed in the latitude dimension. Below is an example how you can reproject the data to CH1903+ / LV95 (EPSG:2056), also known as \"SwissGrid\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default lat and lon use EPSG:4326 which is the CRS used to store SDC data.\n",
    "# Let's reproject the xarray.Dataset into (in our case Swiss CRS) CH1903+ / LV95 (EPSG:2056).\n",
    "dataset_CH = ndvi.rio.set_crs(\"epsg:4326\").rio.reproject(\"epsg:2056\")\n",
    "\n",
    "# xarray.Dataset CRS metadata remains in previous CRS\n",
    "# let's update metadata\n",
    "dataset_CH.attrs['crs'] = 'EPSG:2056'\n",
    "dataset_CH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the dimensions have changed from `latitude, longitude, time` to `x, y, time`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the mosaic again. We will see that the coordinate axes have changed and now represent the familiar Swissgrid. <span class='dothis'>Compare it</span> to the lat/lon images we made earlier in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mosaic again\n",
    "plt.figure()\n",
    "ax = plt.subplot(111, aspect='equal')\n",
    "p = dataset_CH.isel(time=0).plot.imshow(robust=True)\n",
    "# Make the x and y coordinates equally spaced.\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_CH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note how the coordinate units have changed from degrees to metres, compared to the previous plots.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You cannot use the `write_geotiff_from_xr()` function to export datasets that are in SwissGrid, it will cause an error. Use instead the `rio.to_raster()` function which we used already earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_CH.isel(time=2).rio.to_raster(\"ndvi_swissgrid.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Open Data Cube)",
   "language": "python",
   "name": "odc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
