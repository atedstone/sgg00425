{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of functions load\\_multi\\_clean from*./swiss_utils/data_cube_utilities/sdc_utilities.py*\n",
    "\n",
    "*****\n",
    "\n",
    "__This script is the \"official demo\" of a function. Please if you want to modify it, work on your own copy__\n",
    "\n",
    "Creates a clean dataset (multi-product or not) using cleaning \"autor's recommended ways\":\n",
    "- ls_qa_clean\n",
    "- create_slc_clean_mask\n",
    "\n",
    "Scene without any data removed, sorted by ascending time\n",
    "\n",
    "Works with Landsat or Sentinel 2 (but not mixed, see [demo_FUN_mix_lss2](demo_FUN_mix_lss2.ipynb) for this purpose) or with any other product available.\n",
    "\n",
    "* products:     list of products\n",
    "* valid_cats:   array of ints representing what category should be considered valid\n",
    "      * category selected by default\n",
    "      # SENTINEL 2 ################################\n",
    "      #   0 - no data                             #\n",
    "      #   1 - saturated or defective              #\n",
    "      #   2 - dark area pixels                    #\n",
    "      #   3 - cloud_shadows                       #\n",
    "      #   4 * vegetation                          #\n",
    "      #   5 * not vegetated                       #\n",
    "      #   6 * water                               #\n",
    "      #   7 * unclassified                        #\n",
    "      #   8 - cloud medium probability            #\n",
    "      #   9 - cloud high probability              #\n",
    "      #  10 - thin cirrus                         #\n",
    "      #  11 * snow                                #\n",
    "      #############################################\n",
    "      # LANDSAT 5, 7 and 8 ########################\n",
    "      #    0 : Fill                               #\n",
    "      #    1 * Clear                              #\n",
    "      #    2 * Water                              #\n",
    "      #    3 : Cloud shadow                       #\n",
    "      #    4 * Snow                               #\n",
    "      #    5 : Cloud                              #\n",
    "      #   10 : Terrain occlusion (Landsat 8 only) #\n",
    "      #############################################\n",
    "      any other default argument from dc.load (time, lon, lat, output_crs, resolution, resampling,...)\n",
    "\n",
    "Documentation for a given function can be accessed simply by adding ? at the end of the function in a cell. e.g. `load_multi_clean?` or by selecting the function and pressing `Shift-Tab`.\n",
    "\n",
    "In this demo Jupyter script, the user can either use the in-script function (below) or import it from ./swiss_utils/data_cube_utilities/sdc_utilities.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the script is using the proper kernel\n",
    "try:\n",
    "    %run ../swiss_utils/assert_env.py\n",
    "except:\n",
    "    %run ./swiss_utils/assert_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "# reload module before executing code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# define modules locations (you might have to adapt define_mod_locs.py)\n",
    "%run ../swiss_utils/define_mod_locs.py\n",
    "\n",
    "# to plot figures\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import datacube\n",
    "dc = datacube.Datacube()\n",
    "\n",
    "# silence warning (not recommended during development)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# AND THE FUNCTION\n",
    "from swiss_utils.data_cube_utilities.sdc_utilities import load_multi_clean"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "def create_slc_clean_mask(slc, valid_cats = [4, 5, 6, 7, 11]):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "      Create a Sentinel 2 clean mask from a list of valid categories applied on slc band\n",
    "    Input:\n",
    "      slc (xarray) - Sentinel 2 slc band\n",
    "    Args:\n",
    "      slc: xarray data array to extract clean categories from.\n",
    "      valid_cats: array of ints representing what category should be considered valid.\n",
    "      * category selected by default\n",
    "      ###################################\n",
    "      # slc categories:                 #\n",
    "      #   0 - no data                   #\n",
    "      #   1 - saturated or defective    #\n",
    "      #   2 - dark area pixels          #\n",
    "      #   3 - cloud_shadows             #\n",
    "      #   4 * vegetation                #\n",
    "      #   5 * not vegetated             #\n",
    "      #   6 * water                     #\n",
    "      #   7 * unclassified              #\n",
    "      #   8 - cloud medium probability  #\n",
    "      #   9 - cloud high probability    #\n",
    "      #  10 - thin cirrus               #\n",
    "      #  11 * snow                      #\n",
    "      ###################################\n",
    "    Output:\n",
    "      clean_mask (boolean numpy array)\n",
    "    \"\"\"\n",
    "\n",
    "    return xr.apply_ufunc(np.isin, slc, valid_cats).values\n",
    "\n",
    "# Return unique values and count\n",
    "def unik_count(vals):\n",
    "    bc = vals.flatten()\n",
    "    bc = np.bincount(bc)\n",
    "    unik = np.nonzero(bc)[0]\n",
    "    cnt = bc[unik] * 100\n",
    "    return (unik, cnt)\n",
    "\n",
    "# Return bit length\n",
    "def bit_length(int_type):\n",
    "    length = 0\n",
    "    while (int_type):\n",
    "        int_type >>= 1\n",
    "        length += 1\n",
    "    return(length)\n",
    "\n",
    "def ls_qa_clean(dc_qa, valid_bits = [1, 2, 4]):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "      create a clean mask of a Landsat Collection 1 dataset using pixel_qa band and a list of valid bits\n",
    "    Args:\n",
    "      dc_qa: pixel_qa band of a Landast Collection 1 xarray.DataArray\n",
    "      valid_bits: array of ints representing which bit should be considered as valid (default: clear, water, snow)\n",
    "      * category selected by default\n",
    "      #############################################\n",
    "      # BITS : CATEGORIES                         #\n",
    "      #    0 : Fill                               #\n",
    "      #    1 * Clear                              #\n",
    "      #    2 * Water                              #\n",
    "      #    3 : Cloud shadow                       #\n",
    "      #    4 * Snow                               #\n",
    "      #    5 : Cloud                              #\n",
    "      #   10 : Terrain occlusion (Landsat 8 only) #\n",
    "      #############################################\n",
    "    Output:\n",
    "      clean_mask (boolean numpy array)\n",
    "    \"\"\"\n",
    "\n",
    "    # Check submitted input\n",
    "    if str(type(dc_qa)) != \"<class 'xarray.core.dataarray.DataArray'>\":\n",
    "        sys.exit(\"SCRIPT INTERRUPTED: dc_qa should be an xarray.DataArray\")\n",
    "    if dc_qa.name != \"pixel_qa\":\n",
    "        sys.exit(\"SCRIPT INTERRUPTED: dc_qa name  should be pixel_qa\")\n",
    "\n",
    "    # List and count all dc_qa unique values\n",
    "    dc_qas, dc_cnt = unik_count(dc_qa.values)\n",
    "    # Return bit encoding\n",
    "    bit_len = bit_length(max(dc_qas))\n",
    "\n",
    "    # First keep only low confidence cloud (and cirrus)\n",
    "    ok_qas = []\n",
    "    ko_qas = []\n",
    "\n",
    "    if bit_len == 8: # Landsat 5 and 7\n",
    "        for v in sorted(dc_qas):\n",
    "            b = str(bin(v))[2:].zfill(bit_len)[::-1]\n",
    "            if b[6] == '1' and b[7] == '0':\n",
    "                ok_qas.append(v)\n",
    "            else:\n",
    "                ko_qas.append(v)\n",
    "\n",
    "    if bit_len >= 10: # Landsat 8 (>= as sometimes pixel_qa become 11 bit !!!)\n",
    "        for v in sorted(dc_qas):\n",
    "            b = str(bin(v))[2:].zfill(bit_len)[::-1]\n",
    "            if b[6] == '1' and b[7] == '0' and b[8] == '1' and b[9] == '0':\n",
    "                ok_qas.append(v)\n",
    "            else:\n",
    "                ko_qas.append(v)\n",
    "\n",
    "    # Second keep only valid_bits\n",
    "    data_qas = []\n",
    "    nodata_qas = []\n",
    "    for v in sorted(ok_qas):\n",
    "        b = str(bin(v))[2:].zfill(bit_len)[::-1]\n",
    "        for c in valid_bits:\n",
    "            if b[c] == '1':\n",
    "                data_qas.append(v)\n",
    "                break\n",
    "\n",
    "    return xr.apply_ufunc(np.isin, dc_qa, data_qas, dask = 'allowed').values\n",
    "\n",
    "def load_multi_clean(dc, products, measurements, valid_cats = [], **kwargs):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "      Create a clean dataset (multi-product or not) using cleaning \"autor's recommended ways\"\n",
    "      - ls_qa_clean\n",
    "      - create_slc_clean_mask\n",
    "      Scene without any data removed, sorted by ascending time \n",
    "    Input:\n",
    "      dc:           datacube.api.core.Datacube\n",
    "                    The Datacube instance to load data with.\n",
    "    Args:\n",
    "      products:     list of products\n",
    "      valid_cats:   array of ints representing what category should be considered valid\n",
    "                    * category selected by default\n",
    "      # SENTINEL 2 ################################\n",
    "      #   0 - no data                             #\n",
    "      #   1 - saturated or defective              #\n",
    "      #   2 - dark area pixels                    #\n",
    "      #   3 - cloud_shadows                       #\n",
    "      #   4 * vegetation                          #\n",
    "      #   5 * not vegetated                       #\n",
    "      #   6 * water                               #\n",
    "      #   7 * unclassified                        #\n",
    "      #   8 - cloud medium probability            #\n",
    "      #   9 - cloud high probability              #\n",
    "      #  10 - thin cirrus                         #\n",
    "      #  11 * snow                                #\n",
    "      #############################################\n",
    "      # LANDSAT 5, 7 and 8 ########################\n",
    "      #    0 : Fill                               #\n",
    "      #    1 * Clear                              #\n",
    "      #    2 * Water                              #\n",
    "      #    3 : Cloud shadow                       #\n",
    "      #    4 * Snow                               #\n",
    "      #    5 : Cloud                              #\n",
    "      #   10 : Terrain occlusion (Landsat 8 only) #\n",
    "      #############################################\n",
    "      any other default argument from dc.load (time, lon, lat, output_crs, resolution, resampling,...)\n",
    "      \n",
    "    Output:\n",
    "      cleaned dataset and clean_mask sorted by ascending time\n",
    "    Authors:\n",
    "      Bruno Chatenoux (UNEP/GRID-Geneva, 15.03.2022)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check submitted input\n",
    "    # Convert product string into list\n",
    "    if isinstance(products, str):\n",
    "        products = products.split()\n",
    "        \n",
    "    # Get common measurements\n",
    "    common_measurements = []\n",
    "    measurement_list = dc.list_measurements(with_pandas=False)\n",
    "    for product in products:\n",
    "        measurements_for_product = filter(lambda x: x['product'] == product, measurement_list)\n",
    "        common_measurements.append(set(map(lambda x: x['name'], measurements_for_product)))\n",
    "    common_measurements = list(set.intersection(*map(set, common_measurements)))\n",
    "    assert len(common_measurements) > 0, \\\n",
    "           '! No common measurements found'\n",
    "    \n",
    "    # Check requested measurements are in common measurements\n",
    "    assert all([item in common_measurements for item in measurements]), \\\n",
    "           f\"\"\"\n",
    "           All requested measures are not available for each product\n",
    "           Only {common_measurements} are available\n",
    "           \"\"\"\n",
    "    \n",
    "    # Add quality measurement for Landsat or Sentinel 2 products\n",
    "    # using the first product as they shouldn't be mixed\n",
    "    if products[0][:2] == 'ls' and 'pixel_qa' not in measurements:\n",
    "        measurements.append('pixel_qa')\n",
    "    elif products[0][:2] == 's2' and 'slc' not in measurements:\n",
    "        measurements.append('slc')\n",
    "    \n",
    "    # Load and combine dataset\n",
    "    ds_out = None\n",
    "    for product in products:\n",
    "        # load product dataset\n",
    "        ds_tmp = dc.load(product = product, measurements = measurements, **kwargs)        \n",
    "        \n",
    "        if len(ds_tmp.variables) == 0: continue # skip the current iteration if empty\n",
    "\n",
    "        # clean product dataset\n",
    "        if products[0][:2] == 'ls':\n",
    "            if len(valid_cats) == 0: valid_cats = [1, 2, 4]\n",
    "            clean_mask_tmp = ls_qa_clean(ds_tmp.pixel_qa, valid_cats)\n",
    "        elif products[0][:2] == 's2':\n",
    "            if len(valid_cats) == 0: valid_cats = [4, 5, 6, 7, 11]\n",
    "            clean_mask_tmp = create_slc_clean_mask(ds_tmp.slc, valid_cats)\n",
    "        ds_tmp = ds_tmp.where(clean_mask_tmp)\n",
    "        \n",
    "        # remove time without any data\n",
    "        ds_tmp = ds_tmp.dropna('time', how='all')\n",
    "        \n",
    "        # initiate or append to dataset to return\n",
    "        if ds_out is None:\n",
    "            ds_out = ds_tmp.copy(deep=True)\n",
    "        else:\n",
    "            ds_out = xr.concat([ds_out, ds_tmp], dim = 'time')\n",
    "        del ds_tmp\n",
    "\n",
    "    if ds_out is not None:\n",
    "        # sort dataset by ascending time\n",
    "        ds_out = ds_out.sortby('time')\n",
    "        return (ds_out, ~np.isnan(ds_out[measurements[0]].values))\n",
    "    else:\n",
    "        return (0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell contains the dataset configuration information:\n",
    "- product(s) (could be either a single product (e.g. ''ls8_lasrc_swiss') or list (e.g. ['ls8_lasrc_swiss', 'ls7_ledaps_swiss'])\n",
    "- geographical extent\n",
    "- time period\n",
    "- measurements (bands)\n",
    "\n",
    "You can generate it in three ways, but before to do it **keep in mind, this notebook will require Landsat product(s) with at least ['green', 'pixel_qa']**.\n",
    "1. manually from scratch,\n",
    "2. by manually copy/pasting the final cell content of the [config_tool](config_tool.ipynb) notebook,\n",
    "3. by loading the final cell content of the [config_tool](config_tool.ipynb) notebook using the magic `# %load config_cell.txt`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load config_cell.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load and clean a demo dasatet\n",
    "\n",
    "dataset_clean, clean_mask = load_multi_clean(dc = dc, products = product, time = [start_date, end_date],\n",
    "                                          lon = [min_lon, max_lon], lat = [min_lat, max_lat],\n",
    "                                          measurements = measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot blue band for all time keeping only positive values. Notice how the function\n",
    "# remove the scenes without any data\n",
    "\n",
    "dataset_clean.where(dataset_clean >= 0).green.plot(x='longitude', y='latitude',\n",
    "                                                  col='time', col_wrap=5, cmap = 'Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`load_multi_clean` function works also with multiple Landsat sensors. For the demo create manually a configuration cell below with Landsat 8 and 7 products (the last one starting after June 2015):\n",
    "\n",
    "- using the [config_tool](config_tool.ipynb).\n",
    "\n",
    "- replacing for example in the case of the SDC: `product = 'ls8_ledaps_swiss'`\n",
    "by `products = ['ls8_lasrc_swiss', 'ls7_ledaps_swiss']` (notice the **s** in product**s**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration (manually edited)\n",
    "\n",
    "products = ['ls8_lasrc_swiss', 'ls7_ledaps_swiss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using products (with an s) list instead of product string\n",
    "\n",
    "dataset_clean, clean_mask = load_multi_clean(dc = dc, products = products, time = [start_date, end_date],\n",
    "                                          lon = [min_lon, max_lon], lat = [min_lat, max_lat],\n",
    "                                          measurements = measurements)\n",
    "dataset_clean.where(dataset_clean >= 0).green.plot(x='longitude', y='latitude',\n",
    "                                                  col='time', col_wrap=5, cmap = 'Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Open Data Cube Development)",
   "language": "python",
   "name": "odc-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
