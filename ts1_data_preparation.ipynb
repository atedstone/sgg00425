{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TS-1: Data preparation\n",
    "\n",
    "*****\n",
    "\n",
    "This notebook allows you to load and pre-process an SDC dataset, which you can then save into a NetCDF (.nc) file to be reused quickly in other Notebooks where you do your analysis.\n",
    "\n",
    "Things you should change:\n",
    "\n",
    "* The config_cell variables\n",
    "* The output filename of the netcdf file (see the last cell).\n",
    "\n",
    "Then, note that the Notebook has two different options depending on the dataset that you want to pre-process:\n",
    "\n",
    "* Landsat\n",
    "* Land use statistics\n",
    "\n",
    "Only execute the section which corresponds to the product that you specified in the config_cell!\n",
    "\n",
    "*****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "# reload module before executing code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# define modules locations (you might have to adapt define_mod_locs.py)\n",
    "%run ../sdc-notebooks/Tools/define_mod_locs.py\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "    \n",
    "from datetime import datetime\n",
    "\n",
    "from sdc_tools.sdc_utilities import lsc2_loadcleanscale\n",
    "\n",
    "import datacube\n",
    "dc = datacube.Datacube()\n",
    "\n",
    "ds_clean = None\n",
    "ds_astat = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell contains the dataset configuration information:\n",
    "- product\n",
    "- geographical extent\n",
    "- time period\n",
    "- bands\n",
    "\n",
    "You can generate it in three ways:\n",
    "1. manually from scratch,\n",
    "2. by manually copy/pasting the final cell content of the [config_tool](config_tool.ipynb) notebook,\n",
    "3. by loading the final cell content of the [config_tool](config_tool.ipynb) notebook using the magic `%load config_cell.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"config_cell.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose your path now ...\n",
    "## (1) Optical Landsat satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you  like, you can load a longer time series of Landsat by requesting data from each satellite.\n",
    "# Be aware that this will take quite a long time to load. \n",
    "# And only do this for an area a few kilometres/10s kilometres in extent (otherwise you risk requesting too much data!)\n",
    "#products = ['landsat_ot_c2_l2', 'landsat_etm_c2_l2', 'landsat_tm_c2_l2']\n",
    "\n",
    "ds_clean, mask = lsc2_loadcleanscale(dc = dc,\n",
    "                                     products = product,\n",
    "                                     longitude = longitude,\n",
    "                                     latitude = latitude,\n",
    "                                     crs = crs,\n",
    "                                     time = time,\n",
    "                                     measurements = measurements,\n",
    "                                     output_crs = output_crs,\n",
    "                                     resolution = resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_clean = ds_clean.where(ds_clean >= 0) # keep only positive values\n",
    "ds_clean = ds_clean.dropna('time', how='all') # drop scenes without data\n",
    "ds_clean.time.attrs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some necessary small changes so that we can save this dataset to a NetCDF (.nc) file.\n",
    "\n",
    "# Remove quality info attributes\n",
    "if 'pixel_qa' in measurements:\n",
    "    ds_clean.pixel_qa.attrs['flags_definition'] = []\n",
    "elif 'slc' in measurements:\n",
    "    ds_clean.slc.attrs['flags_definition'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: add normalised difference index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL CELL TO CALCULATE NDIs\n",
    "# You can already calculate normalised difference indexes here to be saved with the measurements.\n",
    "# To do this, uncomment the relevant line(s) below and/or add your own.\n",
    "\n",
    "ds_clean['ndvi'] = (ds_clean.nir - ds_clean.red) / (ds_clean.nir + ds_clean.red)\n",
    "ds_clean['ndwi'] = (ds_clean.green - ds_clean.nir) / (ds_clean.green + ds_clean.nir)\n",
    "\n",
    "# Remove time attributes from each of the indices that you define above.\n",
    "ds_clean.ndvi.time.attrs = {}\n",
    "\n",
    "# 'NDWI': '(ds.green - ds.nir) / (ds.green + ds.nir)',\n",
    "# 'NDBI': '(ds.swir2 - ds.nir) / (ds.swir2 + ds.nir)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a quick look at the summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And/or (2) Land use statistics\n",
    "\n",
    "Here, you can either:\n",
    "\n",
    "1. Load land use statistics directly using the information from the `config_cell` that you already loaded above\n",
    "2. Or if you already loaded Landsat data above, you can now load the arealstatistik data at the same resolution for the same area. This secon option requires some choices from you in the box below ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STUFF FOR OPTION 2\n",
    "# Here, we manually change the variables `product` and `measurements` to specify what we want to load from arealstatistik.\n",
    "# We leave longitude, latitude, resolution, output_crs exactly as they were for Landsat. \n",
    "# This ensures that the data from arealstatistik will match the spatial coordinates of Landsat perfectly.\n",
    "\n",
    "# TO PROCEED WITH THIS OPTION, UNCOMMENT AND EDIT 2 CODE LINES BELOW!\n",
    "\n",
    "# Specify the arealstatistik product\n",
    "# product = ['arealstatistik']\n",
    "\n",
    "# Here, the measurements are not individual colour bands, \n",
    "# but instead are the different surveys with the desired number of classes.\n",
    "# In this example, we are loading the 27-class measurements for two time periods: the one ending 1985 and the one ending 2018.\n",
    "# measurements = ['AS85_27','AS18_27']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time is not relevant for the arealstatistik products, so we don't include it as a keyword here.\n",
    "ds_astat = dc.load(product = product,\n",
    "                measurements = measurements,\n",
    "                longitude = longitude,\n",
    "                latitude = latitude,\n",
    "                output_crs = output_crs, \n",
    "                resolution = resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a quick look at the summary of these data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_astat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, figure out if we need to combine Landsat data with arealstatistik.\n",
    "\n",
    "if (ds_clean is not None) and (ds_astat is not None):\n",
    "    # In this case, you have loaded both Landsat and arealstatistik.\n",
    "    # So, let's combine them into a single Dataset, allowing them to be saved together.\n",
    "    ds_save = xr.merge([ds_clean, ds_astat])\n",
    "elif (ds_clean is not None):\n",
    "    # We are saving only the Landsat dataset\n",
    "    ds_save = ds_clean\n",
    "elif (ds_astat is not None):\n",
    "    # We are saving only the arealstatistik dataset\n",
    "    ds_save = ds_astat\n",
    "else:\n",
    "    raise ValueError('Hmm, unknown combination of data. Ask a teacher for help.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is what will be saved..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file. Change the output filename to something useful!\n",
    "output_filename = 'myfile.nc'\n",
    "ds_save.to_netcdf(output_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Open Data Cube Development)",
   "language": "python",
   "name": "odc-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
